<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ArcherSense Generator V2 (Portrait)</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js" crossorigin="anonymous"></script>

  <style>
    body {
      margin: 0;
      background-color: #000;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      overflow: hidden;
      font-family: sans-serif;
    }
    
    /* Container füllt den Screen im Hochformat */
    .container {
      position: relative;
      width: 100vw;
      height: 100vh;
    }

    /* Video verstecken */
    .input_video { 
        display: none; 
        /* Wir drehen das Video-Element virtuell, falls nötig, 
           aber MediaPipe regelt die Orientierung meist selbst gut */
    }

    /* Canvas füllt den Screen, behält aber Aspect Ratio */
    .output_canvas {
      width: 100%;
      height: 100%;
      object-fit: cover;
      background-color: #1a2111; /* Dein App Background */
    }

    #status {
      position: absolute;
      top: 40px; /* Tiefer für Mobile Notch/Leiste */
      left: 20px;
      right: 20px;
      text-align: center;
      color: #74b814;
      background: rgba(0,0,0,0.7);
      padding: 15px;
      border-radius: 12px;
      font-size: 18px;
      pointer-events: none;
      z-index: 10;
    }
  </style>
</head>

<body>
  <div class="container">
    <div id="status">Starte Rückkamera...</div>
    <video class="input_video" playsinline autoplay muted></video>
    <canvas class="output_canvas" width="1080" height="1920"></canvas>
  </div>

  <script type="module">
    const videoElement = document.getElementsByClassName('input_video')[0];
    const canvasElement = document.getElementsByClassName('output_canvas')[0];
    const canvasCtx = canvasElement.getContext('2d');
    const statusDiv = document.getElementById('status');
    
    let isPaused = false;

    // Klick Handler
    document.body.addEventListener('click', () => {
        isPaused = !isPaused;
        statusDiv.innerText = isPaused ? "PAUSIERT (Screenshot machen!)" : "Live Tracking...";
        statusDiv.style.color = isPaused ? "#ff5555" : "#74b814";
    });

    function onResults(results) {
      if (isPaused) return;

      // 1. Hintergrund
      canvasCtx.fillStyle = '#1a2111'; // Oder '#000000' für Screen-Mode
      canvasCtx.fillRect(0, 0, canvasElement.width, canvasElement.height);

      // 2. Skelett zeichnen (JETZT FETTER)
      if (results.poseLandmarks) {
        // Verbindungen (Knochen)
        drawConnectors(canvasCtx, results.poseLandmarks, POSE_CONNECTIONS,
                       {color: '#FFFFFF', lineWidth: 12}); // Vorher 4 -> Jetzt 12
        
        // Gelenke (Punkte)
        drawLandmarks(canvasCtx, results.poseLandmarks,
                      {color: '#74b814', lineWidth: 4, radius: 15}); // Radius 6 -> 15
      }
      
      if (statusDiv.innerText.includes("Starte") || statusDiv.innerText.includes("Lade")) {
          statusDiv.innerText = "Klick auf Screen = Pause/Freeze";
      }
    }

    const pose = new Pose({locateFile: (file) => {
      return `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`;
    }});
    
    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });
    pose.onResults(onResults);

    // Manueller Kamera-Start für Rückkamera (Environment)
    async function startCamera() {
        try {
            const constraints = {
                video: {
                    facingMode: 'environment', // Zwingt Rückkamera
                    width: { ideal: 1080 },
                    height: { ideal: 1920 }
                }
            };
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            videoElement.srcObject = stream;
            
            // Loop starten sobald Video läuft
            videoElement.onloadedmetadata = () => {
                videoElement.play();
                requestAnimationFrame(processVideo);
            };
        } catch (err) {
            statusDiv.innerText = "Kamera-Fehler: " + err.name;
            console.error(err);
        }
    }

    // Eigene Loop statt Camera Utils (für mehr Kontrolle)
    async function processVideo() {
        if (!videoElement.paused && !videoElement.ended) {
            await pose.send({image: videoElement});
        }
        // Immer weiter loopen
        requestAnimationFrame(processVideo);
    }

    startCamera();
  </script>
</body>
</html>